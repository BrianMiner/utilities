{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Several things here:\n",
    "\n",
    "1) Running  a 1 D convol for text (comes from keras examples)\n",
    "2) replicating the 2d convol from cs231n demo\n",
    "3) See how to look at the output of each layer, to understand what is happening"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Demonstrate using a 1-D convolution on text data</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:80% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:80% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "25000 train sequences\n",
      "25000 test sequences\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "\n",
    "Download the data\n",
    "\n",
    "'''\n",
    "import os\n",
    "#to force tensorflow to run on CPU\n",
    "#http://stackoverflow.com/questions/40690598/can-keras-with-tensorflow-backend-be-forced-to-use-cpu-or-gpu-at-will\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\"\n",
    "\n",
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "np.random.seed(1337)  # for reproducibility\n",
    "\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import Convolution1D, MaxPooling1D, Convolution2D, MaxPooling2D, GlobalAveragePooling1D, MaxPooling2D\n",
    "from keras.datasets import imdb\n",
    "from keras import backend as K\n",
    "from keras.layers.convolutional import ZeroPadding2D\n",
    "\n",
    "\n",
    "max_features = 5000\n",
    "\n",
    "print('Loading data...')\n",
    "\n",
    "#Top most frequent words to consider. Any less frequent word (than max_features) will appear as 0 in the sequence data\n",
    "(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words=max_features)\n",
    "print(len(X_train), 'train sequences')\n",
    "print(len(X_test), 'test sequences')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 14, 22, 16, 43, 530, 973, 1622, 1385, 65, 458, 4468, 66, 3941, 4, 173, 36, 256, 5, 25, 100, 43, 838, 112, 50, 670, 2, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 2, 336, 385, 39, 4, 172, 4536, 1111, 17, 546, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2025, 19, 14, 22, 4, 1920, 4613, 469, 4, 22, 71, 87, 12, 16, 43, 530, 38, 76, 15, 13, 1247, 4, 22, 17, 515, 17, 12, 16, 626, 18, 2, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2223, 2, 16, 480, 66, 3785, 33, 4, 130, 12, 16, 38, 619, 5, 25, 124, 51, 36, 135, 48, 25, 1415, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 2, 8, 4, 107, 117, 2, 15, 256, 4, 2, 7, 3766, 5, 723, 36, 71, 43, 530, 476, 26, 400, 317, 46, 7, 4, 2, 1029, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2071, 56, 26, 141, 6, 194, 2, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 2, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 1334, 88, 12, 16, 283, 5, 16, 4472, 113, 103, 32, 15, 16, 2, 19, 178, 32]\n",
      "218\n",
      "189\n"
     ]
    }
   ],
   "source": [
    "#first review is a list of integers for each token and the length is 218. Length of second is 189\n",
    "\n",
    "print(X_train[0])\n",
    "\n",
    "print(len(X_train[0]))\n",
    "print(len(X_train[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pad sequences (samples x time)\n",
      "X_train shape: (25000, 400)\n",
      "X_test shape: (25000, 400)\n",
      "\n",
      "\n",
      "\n",
      "So, we see above that each example is 400 numbers - these words are already preprocessed this way:\n",
      "\n",
      "[   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    1   14   22   16   43  530  973 1622 1385   65  458 4468   66\n",
      " 3941    4  173   36  256    5   25  100   43  838  112   50  670    2    9\n",
      "   35  480  284    5  150    4  172  112  167    2  336  385   39    4  172\n",
      " 4536 1111   17  546   38   13  447    4  192   50   16    6  147 2025   19\n",
      "   14   22    4 1920 4613  469    4   22   71   87   12   16   43  530   38\n",
      "   76   15   13 1247    4   22   17  515   17   12   16  626   18    2    5\n",
      "   62  386   12    8  316    8  106    5    4 2223    2   16  480   66 3785\n",
      "   33    4  130   12   16   38  619    5   25  124   51   36  135   48   25\n",
      " 1415   33    6   22   12  215   28   77   52    5   14  407   16   82    2\n",
      "    8    4  107  117    2   15  256    4    2    7 3766    5  723   36   71\n",
      "   43  530  476   26  400  317   46    7    4    2 1029   13  104   88    4\n",
      "  381   15  297   98   32 2071   56   26  141    6  194    2   18    4  226\n",
      "   22   21  134  476   26  480    5  144   30    2   18   51   36   28  224\n",
      "   92   25  104    4  226   65   16   38 1334   88   12   16  283    5   16\n",
      " 4472  113  103   32   15   16    2   19  178   32]\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "maxlen = 400\n",
    "\n",
    "#maxlen : maximum sequence length, longer sequences are truncated \n",
    "#and shorter sequences are padded with zeros at the end.\n",
    "\n",
    "print('Pad sequences (samples x time)')\n",
    "X_train = sequence.pad_sequences(X_train, maxlen=maxlen)\n",
    "X_test = sequence.pad_sequences(X_test, maxlen=maxlen)\n",
    "print('X_train shape:', X_train.shape)\n",
    "print('X_test shape:', X_test.shape)\n",
    "\n",
    "print(\"\\n\\n\")\n",
    "print(\"So, we see above that each example is 400 numbers - these words are already preprocessed this way:\\n\")\n",
    "print(X_train[0])\n",
    "\n",
    "#We see the padding by default is on the left\n",
    "\n",
    "#This changed the shape. It is now 2d numpy array where \n",
    "#each row is a review and each column is a 0 or integer indexing the word\n",
    "print(type(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# set parameters:\n",
    "\n",
    "embedding_dims = 50 \n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "\n",
    "\n",
    "model.add(Embedding(input_dim=max_features+1, #Size of the vocabulary, \n",
    "                                            #ie. 1 + maximum integer index occurring in the input data to account for 0\n",
    "                    output_dim=embedding_dims, #Dimension of the dense embedding (each token integer is mapped to a output_dim dimensional desne numeric vector)\n",
    "                    input_length=maxlen, #Length of input sequences, when it is constant\n",
    "                    mask_zero =False)) #convolution1d does not support masking: https://stackoverflow.com/questions/43392693/how-to-input-mask-value-to-convolution1d-layer\n",
    "\n",
    "\n",
    "\n",
    "model.compile('rmsprop', 'mse')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 400, 50)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#pass through the first example review\n",
    "output_array = model.predict(X_train[0:1])\n",
    "#note X_train[0].shape is be shape (400,1) and error results: ValueError: Error when checking : expected embedding_1_input to have shape (None, 400) but got array with shape (400, 1)\n",
    "#While X_train[0:1] will be shape (1,400) which conforms to expected (batch,400) \n",
    "\n",
    "\n",
    "\n",
    "#result on first review:\n",
    "output_array.shape #is (1, 400, 50) corrsponding to the single review (1), the sequence length (400) and tje word vector length (50). So, each sequence token gets a 50 dimension vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "These are the embedding vectors:\n",
      "[[[-0.04300938  0.04198356 -0.0022753  -0.0404867   0.04836346]\n",
      "  [-0.02434923 -0.00514651 -0.03838418 -0.00085073  0.02251348]\n",
      "  [-0.00879489  0.03876739 -0.04208625 -0.03341036 -0.00847604]\n",
      "  [-0.04300938  0.04198356 -0.0022753  -0.0404867   0.04836346]]\n",
      "\n",
      " [[-0.04300938  0.04198356 -0.0022753  -0.0404867   0.04836346]\n",
      "  [-0.02434923 -0.00514651 -0.03838418 -0.00085073  0.02251348]\n",
      "  [-0.00879489  0.03876739 -0.04208625 -0.03341036 -0.00847604]\n",
      "  [-0.00879489  0.03876739 -0.04208625 -0.03341036 -0.00847604]]\n",
      "\n",
      " [[-0.02434923 -0.00514651 -0.03838418 -0.00085073  0.02251348]\n",
      "  [-0.04300938  0.04198356 -0.0022753  -0.0404867   0.04836346]\n",
      "  [-0.04300938  0.04198356 -0.0022753  -0.0404867   0.04836346]\n",
      "  [-0.02434923 -0.00514651 -0.03838418 -0.00085073  0.02251348]]]\n",
      "\n",
      "Shape of embedding vectors:\n",
      "(3, 4, 5)\n",
      "\n",
      "This is the filter:\n",
      "[[[  0.   1.]\n",
      "  [  2.   3.]\n",
      "  [  4.   5.]\n",
      "  [  6.   7.]\n",
      "  [  8.   9.]]\n",
      "\n",
      " [[ 10.  11.]\n",
      "  [ 12.  13.]\n",
      "  [ 14.  15.]\n",
      "  [ 16.  17.]\n",
      "  [ 18.  19.]]\n",
      "\n",
      " [[ 20.  21.]\n",
      "  [ 22.  23.]\n",
      "  [ 24.  25.]\n",
      "  [ 26.  27.]\n",
      "  [ 28.  29.]]]\n",
      "\n",
      "As expected its shape is (filter height, length of word vectors, number of filters): \n",
      "(3, 5, 2)\n",
      "\n",
      "first filter:\n",
      "[[  0.   2.   4.   6.   8.]\n",
      " [ 10.  12.  14.  16.  18.]\n",
      " [ 20.  22.  24.  26.  28.]]\n",
      "\n",
      "\n",
      "Shape of the output from the convolution\n",
      "(1, 2, 2)\n",
      "\n",
      "\n",
      "The output of the convolution- just two numbers from each filter\n",
      "[[[-1.67122853 -1.76687026]\n",
      "  [-0.57754254 -0.67318428]]]\n",
      "\n",
      "\n",
      "The output of the convolution- for the first filter\n",
      "[[-1.67122853 -0.57754254]]\n"
     ]
    }
   ],
   "source": [
    "#lets examime what a Convolution1D layer does with a small example.\n",
    "\n",
    "np.random.seed(123)\n",
    "\n",
    "#input is (3,4) integers. This would be like 3 examples where there are 4 words in each example and our vocabulary only consists of 3 words\n",
    "X=np.array(([1,2,3,1],[1,2,3,3],[2,1,1,2]))\n",
    "X.shape\n",
    "\n",
    "mod_embed=Sequential()\n",
    "mod_embed.add(Embedding(input_dim=3+1, #Size of the vocabulary, ie. 1 + maximum integer index occurring in the input data\n",
    "                    output_dim=5, #Dimension of the dense embedding\n",
    "                    input_length=4, #Length of input sequences, when it is constant\n",
    "                    mask_zero =False)) \n",
    "\n",
    "print(\"\\nThese are the embedding vectors:\")\n",
    "print(mod_embed.predict(X))\n",
    "print(\"\\nShape of embedding vectors:\")\n",
    "print(mod_embed.predict(X).shape) #3,4,5 each of the 4 words is mapped to a 4 dimensional row vector (Note that the same word (integer) is related to the same vector within and across examples - i.e. a token of '2' will be the same word vector within this example and all other examples)\n",
    "\n",
    "#save out first embedding\n",
    "np.savetxt('/home/jma/Documents/saved_embed.txt', mod_embed.predict(X)[0,:,:])\n",
    "\n",
    "def my_init(shape, dtype=None):\n",
    "    init=np.arange(30).reshape(3,5,2) #(filter height, length of word vectors, number of filters)\n",
    "    return init \n",
    "\n",
    "mod_embed.add(Convolution1D(\n",
    "                        filters=2, #just 2 filter\n",
    "                        kernel_size=3, #filter height (how many words to cover at a time)\n",
    "                        padding='valid', #no padding\n",
    "                        strides=1 ,     \n",
    "                        kernel_initializer=my_init \n",
    "))\n",
    "\n",
    "#save out first filter\n",
    "np.savetxt('/home/jma/Documents/saved_filter.txt',mod_embed.get_weights()[1][:,:,0])\n",
    "\n",
    "print(\"\\nThis is the filter:\")\n",
    "print(mod_embed.get_weights()[1])\n",
    "print(\"\\nAs expected its shape is (filter height, length of word vectors, number of filters): \")\n",
    "print(mod_embed.get_weights()[1].shape)\n",
    "print(\"\\nfirst filter:\")\n",
    "print(mod_embed.get_weights()[1][:,:,0])\n",
    "\n",
    "\n",
    "#this will result in \n",
    "print(\"\\n\\nShape of the output from the convolution\")\n",
    "print(mod_embed.predict(X[0:1]).shape)\n",
    "print(\"\\n\\nThe output of the convolution- just two numbers from each filter\")\n",
    "print(mod_embed.predict(X[0:1]))\n",
    "print(\"\\n\\nThe output of the convolution- for the first filter\")\n",
    "print(mod_embed.predict(X[0:1])[:,:,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at the spreadsheet new_cnnID. You will find the exact output as above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "This (convolutional 1D on text) I guess can be thought of as 'kernel_size' - gram on text, becuase the dot product is \n",
    "over complete rows (the embedding vectors) for several words ('kernel size of them) at a time, then slides foward and so on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Complete example in other notebook called Amazon_CNN_Text\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<h2>Demonstrate using a 2-D convolution on image data</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "http://cs231n.github.io/convolutional-networks/#conv demo is the basis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "zero_padding2d_2 (ZeroPaddin (None, 5, 7, 5)           0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 2, 3, 2)           92        \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 2, 3, 2)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 1, 1, 2)           0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 2)                 0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                30        \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 11        \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 133\n",
      "Trainable params: 133\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jma/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:32: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(2, (3, 3), strides=(2, 2), padding=\"valid\")`\n"
     ]
    }
   ],
   "source": [
    "N = 50\n",
    "X = np.random.randn(N, 3,5, 5)  #creates the 3 channel data, 5x5 matrices\n",
    "y = np.random.randint(1, size=N)\n",
    "#print (X[0,:,:,:])\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "# number of convolutional filters, this is the number of \"neurons\"\n",
    "n_filters = 2\n",
    "\n",
    "# convolution filter size\n",
    "# i.e. we will use a n_conv x n_conv filter\n",
    "n_conv = 3\n",
    "\n",
    "# pooling window size\n",
    "# i.e. we will use a n_pool x n_pool pooling window\n",
    "n_pool = 2\n",
    "\n",
    "model.add(ZeroPadding2D(input_shape=(3, 5, 5),padding=(1,1)))  #this makes a 7x7 data input\n",
    "model.add(Convolution2D(\n",
    "        n_filters, n_conv, n_conv,\n",
    "\n",
    "        # apply the filter to only full parts of the image\n",
    "        # (i.e. do not \"spill over\" the border)\n",
    "        # this is called a narrow convolution\n",
    "        border_mode='valid',\n",
    "\n",
    "        # we have a 5x5 RGB channel\n",
    "        # so the input shape should be (3,5,5)\n",
    "        #input_shape=(3, 5, 5),\n",
    "        \n",
    "        subsample=(2, 2) #this is STRIDE (left to right and top to bottom),\n",
    "        \n",
    "))\n",
    "\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(MaxPooling2D(pool_size=(n_pool, n_pool)))\n",
    "\n",
    "# flatten the data for the 1D layers\n",
    "model.add(Flatten())\n",
    "\n",
    "# Dense(n_outputs)\n",
    "model.add(Dense(10))\n",
    "\n",
    "\n",
    "# the softmax output layer gives us a probablity for each class\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('linear'))\n",
    "\n",
    "model.compile(loss='mse',\n",
    "    optimizer='adam',\n",
    "    metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above we see that the zero padding creates a 7x7 matrix and the convolution outputs 2x3x3 just like the cs\n",
    "231 example demo. \n",
    "\n",
    "Next we should see how many weights there are in Convolution. In the demo there are 2 sets (one for each filter) of 3x3x3 (size of the filter and number of channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# how many examples to look at during each training iteration\n",
    "batch_size = 1\n",
    "\n",
    "# how many times to run through the full set of examples\n",
    "n_epochs = 1\n",
    "\n",
    "model.fit(X,\n",
    "          y,\n",
    "          batch_size=batch_size,\n",
    "          nb_epoch=n_epochs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#SUCCESS!\n",
    "\n",
    "#[0] is the padding, [1] is the convolution\n",
    "#we see that indeed weights are 2x3x3x3!\n",
    "weights=model.layers[1].get_weights()[0]\n",
    "print (weights)\n",
    "print (weights.shape)\n",
    "\n",
    "#and the biases are 2x1!\n",
    "biases=model.layers[1].get_weights()[1]\n",
    "print (biases)\n",
    "print (biases.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now interested in see the input and output to a given layer. \n",
    "This is interesteding to do for toy example for example to be able to \n",
    "see how the layers actually work on data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten,Merge,Input\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import Convolution1D, MaxPooling1D, Convolution2D, MaxPooling2D\n",
    "from keras import backend as K\n",
    "from keras.layers.convolutional import ZeroPadding2D\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "zero_padding2d_4 (ZeroPaddin (None, 5, 7, 5)           0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 2, 3, 2)           92        \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 2, 3, 2)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 1, 1, 2)           0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 2)                 0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 10)                30        \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 1)                 11        \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 133\n",
      "Trainable params: 133\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/1\n",
      "\r",
      " 1/50 [..............................] - ETA: 1s - loss: 2.1887 - acc: 0.0000e+00"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jma/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:34: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(2, (3, 3), strides=(2, 2), padding=\"valid\")`\n",
      "/home/jma/anaconda3/lib/python3.6/site-packages/keras/models.py:848: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50/50 [==============================] - 0s - loss: 0.5142 - acc: 0.5400        \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f802a669c50>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#FIT A SIMPLE MODEL\n",
    "\n",
    "N = 50\n",
    "X = np.random.randn(N, 3,5, 5)  #creates the 3 channel data, 5x5 matrices\n",
    "y = np.random.randint(1, size=N)\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "# number of convolutional filters, this is the number of \"neurons\"\n",
    "n_filters = 2\n",
    "\n",
    "# convolution filter size\n",
    "# i.e. we will use a n_conv x n_conv filter\n",
    "n_conv = 3\n",
    "\n",
    "# pooling window size\n",
    "# i.e. we will use a n_pool x n_pool pooling window\n",
    "n_pool = 2\n",
    "\n",
    "# we have a 5x5 image with RGB channel\n",
    "# so the input shape should be (3,5,5)\n",
    "model.add(ZeroPadding2D(input_shape=(3, 5, 5),padding=(1,1)))  #this makes a 7x7 data input\n",
    "\n",
    "model.add(Convolution2D(\n",
    "        \n",
    "        n_filters, n_conv, n_conv,\n",
    "\n",
    "        # apply the filter to only full parts of the image\n",
    "        # (i.e. do not \"spill over\" the border)\n",
    "        # this is called a narrow convolution\n",
    "        border_mode='valid',\n",
    "\n",
    "\n",
    "        subsample=(2, 2) #this is STRIDE (left to right and top to bottom),\n",
    "        \n",
    "))\n",
    "\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(MaxPooling2D(pool_size=(n_pool, n_pool)))\n",
    "\n",
    "# flatten the data for the 1D layers\n",
    "model.add(Flatten())\n",
    "\n",
    "# Dense(n_outputs)\n",
    "model.add(Dense(10))\n",
    "\n",
    "\n",
    "# the softmax output layer gives us a probablity for each class\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('linear'))\n",
    "\n",
    "model.compile(loss='mse',\n",
    "    optimizer='adam',\n",
    "    metrics=['accuracy'])\n",
    "\n",
    "print (model.summary())\n",
    "\n",
    "\n",
    "\n",
    "# how many examples to look at during each training iteration\n",
    "batch_size = 1\n",
    "\n",
    "# how many times to run through the full set of examples\n",
    "n_epochs = 1\n",
    "\n",
    "model.fit(X,\n",
    "          y,\n",
    "          batch_size=batch_size,\n",
    "          nb_epoch=n_epochs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-d039a35c01bb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#into the convol\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0minput_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-26-d039a35c01bb>\u001b[0m in \u001b[0;36minput_output\u001b[0;34m(layer_index, X, model)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0minput_output\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlayer_index\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mget_layer_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlayer_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlayer_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mlayer_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_layer_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlayer_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "#Function to return the array passed into a layer and the output of the layer to examine how a layer actually works on it's input (X is the small data you pass into the layer of\n",
    "#interest and the index is determined from the summary above (zero based of course):\n",
    "\n",
    "def input_output (layer_index,X,model):\n",
    "    get_layer_output = K.function([model.layers[layer_index].input], [model.layers[layer_index].output])\n",
    "    layer_output = get_layer_output([X])[0]\n",
    "    return (X,layer_output)\n",
    "    \n",
    "\n",
    "#Create small tensor replicating the shape of data coming into the Convolution2D (second layer,index =1)\n",
    "x=np.random.randn(1,5,7, 5) #into the convol\n",
    "\n",
    "input,output =input_output(1,x,model)\n",
    "\n",
    "output.shape\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now try to see about embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[-0.01539054 -0.02353692  0.02032514  0.03455081]\n",
      "  [-0.03127869  0.04872128 -0.02925384 -0.04018258]\n",
      "  [ 0.00702439 -0.03493382  0.0065612   0.03262452]]\n",
      "\n",
      " [[-0.03127869  0.04872128 -0.02925384 -0.04018258]\n",
      "  [-0.03127869  0.04872128 -0.02925384 -0.04018258]\n",
      "  [-0.04798755 -0.01212469 -0.01046811  0.04191699]]\n",
      "\n",
      " [[-0.03127869  0.04872128 -0.02925384 -0.04018258]\n",
      "  [-0.03127869  0.04872128 -0.02925384 -0.04018258]\n",
      "  [-0.04798755 -0.01212469 -0.01046811  0.04191699]]]\n"
     ]
    }
   ],
   "source": [
    "N = 50\n",
    "X = np.array(([0,2,3],[2,2,1],[2,2,1]))\n",
    "\n",
    "model = Sequential()\n",
    "#input length = Size of the vocabulary, ie. 1 + maximum integer index occurring in the input data.\n",
    "#output_dim =Dimension of the dense embedding\n",
    "#inut_length = length of input sequences, when it is constant\n",
    "model.add(Embedding(input_dim=4, output_dim=4, input_length=3))\n",
    "\n",
    "model.compile('rmsprop', 'mse')\n",
    "  \n",
    "output_array = model.predict(X)\n",
    "print (output_array)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
